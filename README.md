# ğŸ›’ Web Scraper AtacadÃ£o - Python 3

Um web scraper automatizado para extrair preÃ§os de produtos do site do AtacadÃ£o, com suporte completo a JavaScript e configuraÃ§Ã£o automÃ¡tica de CEP.

## ğŸš€ Funcionalidades

- âœ… **Selenium WebDriver** - Suporte completo a JavaScript
- âœ… **ConfiguraÃ§Ã£o automÃ¡tica de CEP** - Detecta e preenche modal automaticamente
- âœ… **ExtraÃ§Ã£o precisa de preÃ§os** - Localiza aside especÃ­fico com data-test
- âœ… **Modo Visual e Headless** - Escolha entre monitorar ou executar invisÃ­vel
- âœ… **Monitoramento de mudanÃ§as** - Detecta atualizaÃ§Ãµes dinÃ¢micas de preÃ§o
- âœ… **Screenshots de debug** - Capturas automÃ¡ticas para troubleshooting
- âœ… **ConfiguraÃ§Ã£o JSON** - Sites gerenciados via arquivo de configuraÃ§Ã£o

## ğŸ“‹ PrÃ©-requisitos

- Python 3.12+
- Google Chrome instalado
- ConexÃ£o com internet

## ğŸ› ï¸ InstalaÃ§Ã£o

### 1. Clone o repositÃ³rio
```bash
git clone <seu-repositÃ³rio>
cd mercado/web_scraper
```

### 2. Criar e ativar ambiente virtual
```bash
python3 -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate     # Windows
```

### 3. Instalar dependÃªncias
```bash
pip install selenium beautifulsoup4 requests webdriver-manager
```

## ğŸ“¦ Estrutura do Projeto

```
web_scraper/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ selenium_scraper.py     # Scraper principal com Selenium
â”‚   â””â”€â”€ database.py            # MÃ³dulo SQLite (futuro)
â”œâ”€â”€ data/
â”‚   â””â”€â”€ sites.json            # ConfiguraÃ§Ã£o de sites
â”œâ”€â”€ run_selenium_scraper.py   # Script de execuÃ§Ã£o
â”œâ”€â”€ .gitignore               # Arquivos ignorados pelo Git
â””â”€â”€ README.md               # Este arquivo
```

## ğŸ¯ Como Usar

### Modo Visual (recomendado para debug)
```bash
python run_selenium_scraper.py
```

### Modo Headless (invisÃ­vel)
```bash
python run_selenium_scraper.py --headless
```

## âš™ï¸ ConfiguraÃ§Ã£o

### Editar sites.json
```json
{
    "sites": [
        {
            "name": "Produto AtacadÃ£o",
            "url": "https://www.atacadao.com.br/produto/url-aqui",
            "enabled": true
        }
    ]
}
```

### Configurar CEP
O CEP padrÃ£o Ã© `88070150`. Para alterar, modifique a funÃ§Ã£o `handle_zipcode_modal()` em `selenium_scraper.py`.

## ğŸ”„ Fluxo de Funcionamento

1. **ğŸŒ Carrega pÃ¡gina** do produto
2. **ğŸ  Detecta modal de CEP** automaticamente  
3. **ğŸ“ Preenche CEP** (88070150)
4. **ğŸ¯ Submete formulÃ¡rio** e aguarda carregamento
5. **ğŸ“‹ Localiza aside** com `data-test="product-details-info"`
6. **ğŸ’² Extrai todas as tags** `<p>` do aside
7. **ğŸ¯ Detecta preÃ§os** automaticamente (padrÃ£o R$)
8. **ğŸ“Š Exibe resultados** formatados

## ğŸ“Š Exemplo de Resultado

```
ğŸ·ï¸  SITE 1: AtacadÃ£o Leite 1L
ğŸ”— URL: https://www.atacadao.com.br/leite-longa-vida-aurora-integral-com-tampa-88650-39196/p
ğŸ“… ExtraÃ­do em: 2025-10-05T10:59:29.538661

âœ… ASIDE ENCONTRADO:
   Total de tags <p>: 1

ğŸ’² TAGS <P> EXTRAÃDAS:
   P1:
     TextContent: R$ 4,19
     InnerHTML: R$&nbsp;4,19
     Classes: text-2xl text-neutral-500 font-bold
     ğŸ¯ CONTÃ‰M PREÃ‡O!
```

## ğŸ›¡ï¸ Recursos de SeguranÃ§a

- **Anti-detecÃ§Ã£o**: User-agent personalizado e mascaramento de webdriver
- **Timeouts configurÃ¡veis**: Evita travamentos
- **Error handling**: Tratamento robusto de erros
- **Screenshots automÃ¡ticos**: Debug visual quando necessÃ¡rio

## ğŸ› Troubleshooting

### ChromeDriver nÃ£o encontrado
O webdriver-manager instala automaticamente. Se houver problemas:
```bash
pip install --upgrade webdriver-manager
```

### Timeout ao carregar pÃ¡gina
Aumente o timeout em `wait_for_complete_loading()`:
```python
def wait_for_complete_loading(self, timeout=60):  # Aumentar para 60s
```

### Modal de CEP nÃ£o detectado
Verifique se o site mudou a estrutura. O seletor atual Ã©:
```python
By.NAME, "zipcode"
```

## ğŸ“ Logs e Debug

- **Screenshots**: `debug_screenshot.png` (criado automaticamente)
- **Console output**: Logs detalhados de cada etapa
- **HTML size**: VerificaÃ§Ã£o do tamanho do conteÃºdo carregado

## ğŸ”§ CustomizaÃ§Ã£o

### Alterar CEP padrÃ£o
```python
def handle_zipcode_modal(self, zipcode="SEU_CEP_AQUI"):
```

### Adicionar novos sites
Edite `data/sites.json` e adicione configuraÃ§Ãµes:
```json
{
    "name": "Novo Produto",
    "url": "URL_DO_PRODUTO",
    "enabled": true
}
```

### Modificar seletores
O scraper busca automaticamente por:
- `aside[data-test='product-details-info']`
- Todas as tags `<p>` dentro do aside

## ğŸ“‹ TODO / Melhorias Futuras

- [ ] IntegraÃ§Ã£o com banco de dados SQLite
- [ ] Sistema de notificaÃ§Ãµes de preÃ§o
- [ ] Suporte a mÃºltiplos CEPs
- [ ] Interface web para configuraÃ§Ã£o
- [ ] Agendamento automÃ¡tico de scraping
- [ ] ExportaÃ§Ã£o para CSV/Excel

## ğŸ¤ Contribuindo

1. Fork o projeto
2. Crie sua feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob licenÃ§a MIT. Veja o arquivo `LICENSE` para mais detalhes.

## âš ï¸ Aviso Legal

Este scraper Ã© destinado apenas para fins educacionais e de pesquisa. Respeite os termos de uso dos sites e as polÃ­ticas de rate limiting. O uso responsÃ¡vel Ã© essencial.

---

**Desenvolvido com â¤ï¸ usando Python e Selenium**